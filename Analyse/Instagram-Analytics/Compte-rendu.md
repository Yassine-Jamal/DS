# JAMAL YASSINE

<img src="JAMAL YASSINE CAC2.jpg" style="height:464px;margin-right:432px"/>

# CAC2

# 22007655


# Compte rendu

## Analyse compl√®te de la base de donn√©es "Instagram Analytics Dataset"

# √Ä propos de ce jeu de donn√©e :
Ce fichier contient 30 000 publications Instagram avec des analyses d√©taill√©es collect√©es au cours des 12 derniers mois. Chaque ligne repr√©sente une publication Instagram et inclut des informations sur le type de m√©dia, les indicateurs d'engagement, la port√©e, les impressions, les enregistrements, les partages, les sources de trafic et le taux d'engagement estim√©.

Ce jeu de donn√©es est con√ßu pour simuler des donn√©es Instagram Insights r√©alistes et reproduit le comportement naturel de l'algorithme d'Instagram. Des indicateurs tels que les mentions ¬´ J'aime ¬ª, la port√©e, les impressions, les enregistrements et le nombre d'abonn√©s gagn√©s ont √©t√© g√©n√©r√©s √† l'aide de distributions statistiques r√©alistes afin de refl√©ter les performances typiques des publications Photos, Vid√©os, Reels et Carrousel.

Ce fichier est id√©al pour explorer :
quel type de contenu est le plus performant ;
le lien entre la port√©e, les impressions et l‚Äôengagement ;
les sources de trafic (Explorer, Flux Reels, Hashtags, etc.) qui g√©n√®rent de la visibilit√© ; l‚Äôinfluence
de la longueur des l√©gendes et des hashtags sur la visibilit√©
; la pr√©diction du taux d‚Äôengagement et des tendances de croissance ;
la mod√©lisation des facteurs de succ√®s sur Instagram gr√¢ce √† l‚Äôapprentissage automatique.

Ce fichier ne contient aucune donn√©e r√©elle d'utilisateurs Instagram. Il est enti√®rement synth√©tique et peut √™tre utilis√© sans danger pour la recherche publique, les √©tudes universitaires, les comp√©titions Kaggle et les projets d'analyse des r√©seaux sociaux.


# Pr√©diction du Taux d‚ÄôEngagement Instagram

Analyse de donn√©es Instagram et comparaison de mod√®les de r√©gression pour pr√©dire le taux d‚Äôengagement des publications.

---

## üìë Table des Mati√®res

1. [Introduction et Contexte](#1-introduction-et-contexte)  
2. [Analyse Exploratoire des Donn√©es](#2-analyse-exploratoire-des-donn√©es)  
   2.1 [Chargement et Structure du Dataset](#21-chargement-et-structure-du-dataset)  
   2.2 [Pr√©traitement et Ing√©nierie de Caract√©ristiques](#22-pr√©traitement-et-ing√©nierie-de-caract√©ristiques)  
   2.3 [Gestion des Valeurs Manquantes](#23-gestion-des-valeurs-manquantes)  
   2.4 [Analyse Statistique et Visuelle](#24-analyse-statistique-et-visuelle)  
3. [M√©thodologie de Mod√©lisation](#3-m√©thodologie-de-mod√©lisation)  
   3.1 [S√©paration des Donn√©es (Train/Test)](#31-s√©paration-des-donn√©es-traintest)  
   3.2 [Mod√®les de R√©gression Test√©s](#32-mod√®les-de-r√©gression-test√©s)  
4. [R√©sultats et Comparaison des Mod√®les](#4-r√©sultats-et-comparaison-des-mod√®les)  
   4.1 [R√©gression Lin√©aire](#41-r√©gression-lin√©aire)  
   4.2 [R√©gression Polynomiale](#42-r√©gression-polynomiale)  
   4.3 [R√©gression par Arbre de D√©cision](#43-r√©gression-par-arbre-de-d√©cision)  
   4.4 [R√©gression par For√™t Al√©atoire](#44-r√©gression-par-for√™t-al√©atoire)  
   4.5 [R√©gression SVR](#45-r√©gression-svr)  
   4.6 [Tableau Comparatif des Performances](#46-tableau-comparatif-des-performances)  
5. [Analyse des R√©sultats et Recommandations](#5-analyse-des-r√©sultats-et-recommandations)  
6. [Conclusion](#6-conclusion)  


---

## 1. Introduction et Contexte

Ce projet pr√©sente une analyse d√©taill√©e d‚Äôun jeu de donn√©es r√©el concernant les statistiques d‚Äôengagement de publications Instagram.  
L‚Äôobjectif est de construire et comparer plusieurs **mod√®les de r√©gression** afin de pr√©dire le **taux d‚Äôengagement** (`engagement_rate`) √† partir de diff√©rentes caract√©ristiques li√©es :

- au contenu (type, cat√©gorie, texte),
- √† l‚Äôaudience (reach, impressions, followers gagn√©s),
- √† l‚Äôinteraction (likes, commentaires, partages, enregistrements),
- √† la temporalit√© (date/heure de publication).

Le pipeline suit les √©tapes classiques d‚Äôun projet de Data Science :

- Analyse exploratoire (EDA),
- Pr√©traitement et ing√©nierie de caract√©ristiques,
- Mod√©lisation et √©valuation,
- Comparaison et s√©lection du meilleur mod√®le.

---

## 2. Analyse Exploratoire des Donn√©es

### 2.1 Chargement et Structure du Dataset

Le fichier principal est `Instagram_Analytics.csv`.

- Nombre d‚Äôobservations : **29 999** publications  
- Nombre de variables : **15** colonnes (14 features + 1 cible)

**Variable cible (Y)**  
- `engagement_rate` : taux d‚Äôengagement (en pourcentage)

**Variables d‚Äôentr√©e (X)** (exemples) :

- Engagement direct : `likes`, `comments`, `shares`, `saves`
- Port√©e / audience : `reach`, `impressions`, `followers_gained`
- M√©tadonn√©es texte : `caption_length`, `hashtags_count`
- Temporelle : `upload_date`
- Cat√©gorielles :
  - `media_type` (Reel, Photo, Video, Carousel)
  - `traffic_source` (Home Feed, Hashtags, Reels Feed, External, Profile, Explore)
  - `content_category` (Technology, Fitness, Beauty, Music, Travel, Photography, etc.)

Un premier aper√ßu (`df.shape`, `df.info()`, `df.head()`) permet de confirmer la coh√©rence du fichier et l‚Äôabsence de types anormaux.

### 2.2 Pr√©traitement et Ing√©nierie de Caract√©ristiques

1) Conversion de la date en **datetime** et extraction de caract√©ristiques temporelles :

- `upload_year`
- `upload_month`
- `upload_day_of_week` (0 = Lundi, ..., 6 = Dimanche)
- `upload_hour`

Ces nouvelles features capturent l‚Äôimpact potentiel du moment de publication sur l‚Äôengagement.

2) Encodage des variables cat√©gorielles via **One-Hot Encoding** pour :

- `media_type`
- `traffic_source`
- `content_category`

L‚Äôoption `drop_first=True` est utilis√©e pour r√©duire la multicolin√©arit√© (suppression d‚Äôune cat√©gorie de r√©f√©rence par variable).

3) Cr√©ation d‚Äôun DataFrame nettoy√© :

- Suppression de `post_id` (identifiant sans valeur pr√©dictive),
- Suppression de `upload_date` brute (remplac√©e par les features temporelles),
- Conservation uniquement de features **num√©riques** dans `df_processed`.

### 2.3 Gestion des Valeurs Manquantes

Une v√©rification syst√©matique est r√©alis√©e :

- `df_processed.isnull().sum()`

R√©sultat : aucune valeur manquante d√©tect√©e ‚Üí **aucune imputation n√©cessaire**, ce qui simplifie la suite de la mod√©lisation.

### 2.4 Analyse Statistique et Visuelle

Quelques points clefs :

- La distribution de `engagement_rate` est l√©g√®rement asym√©trique, avec la majorit√© des valeurs dans une plage ‚Äúmod√©r√©e‚Äù et quelques valeurs extr√™mes.
- Des visualisations (histogrammes, boxplots, pairplots, heatmap de corr√©lation) sont utilis√©es pour :
  - explorer les relations entre `engagement_rate` et les variables d‚Äôengagement (likes, comments, shares, reach, etc.),
  - identifier des corr√©lations et des patterns int√©ressants.
- Les √©chelles des variables (`likes`, `reach`, `impressions`, etc.) sont tr√®s diff√©rentes ‚Üí cela motive l‚Äôusage d‚Äôune **normalisation / standardisation** pour les mod√®les sensibles √† l‚Äô√©chelle (comme SVR).

---

## 3. M√©thodologie de Mod√©lisation

### 3.1 S√©paration des Donn√©es (Train/Test)

S√©paration standard en jeu d‚Äôentra√Ænement et jeu de test :

- Cible :  
  `y = df_processed['engagement_rate']`
- Features :  
  `X = df_processed.drop(columns=['engagement_rate'])`

Split :

- 80 % pour l‚Äô**entra√Ænement** (`X_train`, `y_train`)
- 20 % pour le **test** (`X_test`, `y_test`)
- `random_state=42` pour assurer la reproductibilit√©

### 3.2 Mod√®les de R√©gression Test√©s

Cinq mod√®les de r√©gression ont √©t√© entra√Æn√©s et √©valu√©s :

1. R√©gression Lin√©aire
2. R√©gression Polynomiale (degr√© 2)
3. R√©gression par Arbre de D√©cision
4. R√©gression par For√™t Al√©atoire (Random Forest)
5. R√©gression SVR (Support Vector Regression, noyau RBF, avec normalisation pr√©alable)

Les performances sont √©valu√©es selon trois m√©triques :

- **R¬≤** (coefficient de d√©termination)
- **MSE** (Mean Squared Error)
- **RMSE** (Root Mean Squared Error)

---

## 4. R√©sultats et Comparaison des Mod√®les

### 4.1 R√©gression Lin√©aire

Mod√®le de base supposant une relation lin√©aire entre les features et la cible.

- R¬≤ ‚âà 0.0899 (‚âà 9 % de variance expliqu√©e)
- MSE ‚âà 2238.45
- RMSE ‚âà 47.31

Conclusion : le mod√®le explique tr√®s peu la variance, ce qui sugg√®re que la relation entre les variables d‚Äôentr√©e et le taux d‚Äôengagement est fortement **non lin√©aire**.

### 4.2 R√©gression Polynomiale

R√©gression polynomiale de **degr√© 2** (ajout de termes quadratiques et d‚Äôinteractions).

- R¬≤ ‚âà 0.1706 (‚âà 17 %)
- MSE ‚âà 2062.18
- RMSE ‚âà 45.41

La performance est l√©g√®rement meilleure que la r√©gression lin√©aire, mais reste insuffisante au regard de la complexit√© du probl√®me.

### 4.3 R√©gression par Arbre de D√©cision

Mod√®le non param√©trique, bas√© sur des partitions r√©cursives de l‚Äôespace des features.

- R¬≤ ‚âà 0.7126 (‚âà 71 %)
- MSE ‚âà 707.89
- RMSE ‚âà 26.61

C‚Äôest le **meilleur mod√®le** parmi ceux test√©s :

- Forte hausse de R¬≤ par rapport aux mod√®les lin√©aires,
- R√©duction importante de l‚Äôerreur (RMSE).

Cela montre que les arbres capturent tr√®s bien la nature non lin√©aire et les interactions complexes entre les variables.

### 4.4 R√©gression par For√™t Al√©atoire

Ensemble de nombreux arbres de d√©cision, entra√Æn√©s sur des sous-√©chantillons et sous-ensembles de variables.

- R¬≤ ‚âà 0.5900 (‚âà 59 %)
- MSE ‚âà 1015.68
- RMSE ‚âà 31.87

La For√™t Al√©atoire surperforme nettement les mod√®les lin√©aires, mais reste en retrait par rapport √† l‚Äôarbre de d√©cision simple sur ce dataset particulier (param√®tres par d√©faut).

### 4.5 R√©gression SVR

SVR avec noyau RBF, apr√®s **standardisation** des features (StandardScaler).

- R¬≤ ‚âà 0.0899
- MSE ‚âà 2238.45
- RMSE ‚âà 47.31

Performance comparable √† celle de la r√©gression lin√©aire, indiquant que le mod√®le, dans sa configuration par d√©faut, ne parvient pas √† exploiter efficacement les structures non lin√©aires pr√©sentes.

Un tuning des hyperparam√®tres (`C`, `gamma`, `epsilon`) serait n√©cessaire pour am√©liorer ce mod√®le.

### 4.6 Tableau Comparatif des Performances

| Mod√®le                   | R¬≤       | MSE       | RMSE    | Performance          |
|--------------------------|----------|-----------|---------|----------------------|
| R√©gression Lin√©aire      | 0.0899   | 2238.45   | 47.31   | Tr√®s faible          |
| R√©gression Polynomiale   | 0.1706   | 2062.18   | 45.41   | Faible               |
| Arbre de D√©cision        | 0.7126   | 707.89    | 26.61   | Excellent            |
| For√™t Al√©atoire          | 0.5900   | 1015.68   | 31.87   | Tr√®s bon             |
| SVR                      | 0.0899   | 2238.45   | 47.31   | Tr√®s faible          |

---

## 5. Analyse des R√©sultats et Recommandations

### Mod√®le Gagnant : Arbre de D√©cision

L‚Äô**Arbre de D√©cision** est le mod√®le le plus performant :

- R¬≤ ‚âà 0.71
- RMSE ‚âà 26.61

Il explique une grande partie de la variance du taux d‚Äôengagement tout en maintenant une erreur moyenne relativement faible.

### Interpr√©tation

- Les relations entre les variables (`likes`, `comments`, `shares`, `reach`, etc.) et `engagement_rate` sont clairement **non lin√©aires**.
- Les mod√®les d‚Äôarbres sont adapt√©s √† ces structures complexes et aux interactions entre les features.
- La For√™t Al√©atoire est comp√©titive mais sous-performe l‚Äôarbre simple, probablement faute de tuning d‚Äôhyperparam√®tres.

### Recommandations pour Am√©liorer le Mod√®le

1. Optimiser l‚ÄôArbre de D√©cision :
   - Tuning de `max_depth`, `min_samples_split`, `min_samples_leaf`, `max_features`, etc.
2. Am√©liorer la For√™t Al√©atoire :
   - Augmenter `n_estimators`,
   - Ajuster `max_depth`, `max_features`, `min_samples_leaf`, etc.
3. Am√©liorer le SVR :
   - Tuning de `C`, `gamma`, `epsilon` apr√®s standardisation.
4. Feature engineering avanc√© :
   - Ratios (`likes / reach`, `comments / reach`, `shares / reach`, etc.),
   - Cat√©gorisation des heures/jours (cr√©neaux horaires),
   - Interactions sp√©cifiques entre variables d‚Äôengagement et cat√©gories de contenu.
5. Validation plus robuste :
   - Utilisation de la **validation crois√©e** (k-fold),
   - Comparaison de mod√®les d‚Äôensemble plus avanc√©s (Gradient Boosting, XGBoost, LightGBM).

---

## 6. Conclusion

Ce projet montre comment appliquer un pipeline complet de **Data Science** √† un cas r√©el de **marketing digital** (Instagram) :

- Pr√©traitement : extraction de features temporelles, encodage des variables cat√©gorielles, nettoyage.
- EDA : compr√©hension des distributions, corr√©lations, √©chelles.
- Mod√©lisation : comparaison de plusieurs algorithmes de r√©gression.
- R√©sultat : l‚Äô**Arbre de D√©cision** est le meilleur mod√®le test√©, avec un R¬≤ ‚âà 0.71.

M√™me si la performance est d√©j√† satisfaisante, des gains suppl√©mentaires sont possibles via :

- le tuning d‚Äôhyperparam√®tres,
- un feature engineering plus pouss√©,
- l‚Äôutilisation de mod√®les d‚Äôensemble plus puissants.

---

