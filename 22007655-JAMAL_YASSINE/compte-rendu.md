---
# ðŸ“˜ GRAND GUIDE : ANATOMIE D'UN PROJET DATA SCIENCE - DIGITS

Ce document dÃ©cortique chaque Ã©tape du cycle de vie d'un projet de Machine Learning sur le dataset **Digits**. Il est conÃ§u pour passer du niveau "dÃ©butant qui copie du code" au niveau "ingÃ©nieur qui comprend les mÃ©canismes internes".

---

## 1. Le Contexte MÃ©tier et la Mission

### Le ProblÃ¨me (Business Case)
Dans le domaine de la reconnaissance optique de caractÃ¨res (OCR), identifier automatiquement des chiffres manuscrits accÃ©lÃ¨re le traitement de documents scannÃ©s (factures, formulaires bancaires).

*   **Objectif :** CrÃ©er un "Assistant IA" pour lire automatiquement les chiffres manuscrits 0-9
*   **L'Enjeu critique :** La matrice des coÃ»ts d'erreur est asymÃ©trique
    *   Dire "1" au lieu de "7" = erreur bancaire
    *   Dire "0" au lieu de "6" = erreur de lecture de compte
    *   **L'IA doit prioriser la prÃ©cision globale (>95%)**

### Les DonnÃ©es (L'Input)
Dataset **Digits** de Scikit-Learn
*   **X (Features) :** 64 colonnes (pixels d'images 8x8 aplaties). IntensitÃ©s 0-16
*   **y (Target) :** Multi-classe 0-9 (10 chiffres manuscrits)
*   **Taille :** 1797 images

---

## 2. Le Code Python (Laboratoire)

Ce script est votre paillasse de laboratoire. Il contient toutes les manipulations nÃ©cessaires.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Configuration
sns.set_theme(style="whitegrid")
import warnings
warnings.filterwarnings('ignore')

# --- PHASE 1 : ACQUISITION & SIMULATION ---
data = load_digits()
df = pd.DataFrame(data.data, columns=[f"pixel_{i}" for i in range(data.data.shape[1])])
df['target'] = data.target

# Simulation de la rÃ©alitÃ© (DonnÃ©es sales) - 5% NaN
np.random.seed(42)
df_dirty = df.copy()
for col in df.columns[:-1]:
    df_dirty.loc[df_dirty.sample(frac=0.05).index, col] = np.nan

# --- PHASE 2 : DATA WRANGLING (NETTOYAGE) ---
X = df_dirty.drop('target', axis=1)
y = df_dirty['target']

# StratÃ©gie d'imputation
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)
X_clean = pd.DataFrame(X_imputed, columns=X.columns)

# --- PHASE 3 : ANALYSE EXPLORATOIRE (EDA) ---
print("--- Statistiques Descriptives ---")
print(X_clean.iloc[:, :10].describe())

# Visualisation images
plt.figure(figsize=(10, 3))
for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.imshow(data.images[i], cmap="gray")
    plt.title(f"Label : {data.target[i]}")
    plt.axis("off")
plt.suptitle("Exemples d'images Digits", fontsize=14)
plt.tight_layout()
plt.show()

# --- PHASE 4 : PROTOCOLE EXPÃ‰RIMENTAL (SPLIT) ---
X_train, X_test, y_train, y_test = train_test_split(
    X_clean, y, test_size=0.2, random_state=42, stratify=y
)

# --- PHASE 5 : INTELLIGENCE ARTIFICIELLE (RANDOM FOREST) ---
model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

# --- PHASE 6 : AUDIT DE PERFORMANCE ---
y_pred = model.predict(X_test)

print(f"\n--- Accuracy Globale : {accuracy_score(y_test, y_pred)*100:.2f}% ---")
print("\n--- Rapport DÃ©taillÃ© ---")
print(classification_report(y_test, y_pred, target_names=[str(i) for i in range(10)]))

# Visualisation des erreurs
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Matrice de Confusion : RÃ©alitÃ© vs IA')
plt.ylabel('Vrai Chiffre')
plt.xlabel('Chiffre PrÃ©dit')
plt.show()


---

## 3. Analyse Approfondie : Nettoyage (Data Wrangling)

### Le ProblÃ¨me MathÃ©matique du "Vide"
Les algorithmes ML (algÃ¨bre linÃ©aire) ne peuvent pas gÃ©rer `NaN`. Les 5760 valeurs manquantes injectÃ©es (5% Ã— 64 pixels Ã— 1797 lignes) cassent tous les calculs matriciels.

### La MÃ©canique de l'Imputation
`SimpleImputer(strategy='mean')` en 2 Ã©tapes :
1. **fit** : Calcule $\\mu$ (moyenne) par colonne
2. **transform** : Injecte $\\mu$ Ã  chaque trou

### ðŸ’¡ Le Coin de l'Expert (Data Leakage âš ï¸)
*Attention :* Imputation **AVANT** split Train/Test = **ERREUR**
*   Moyenne Train fuit dans Test â†’ scores gonflÃ©s
*   **Solution pro** : `Pipeline([('imputer', SimpleImputer()), ('rf', RandomForest())])`

---

## 4. Analyse Approfondie : Exploration (EDA)

### DÃ©crypter `.describe()`
```
pixel_0: mean=0.0 std=0.0 â†’ inutile (bord noir)
pixel_20: mean=5.2 std=4.6 â†’ informatif (centre image)
```
* **mean >> median** = distribution asymÃ©trique
* **stdâ‰ˆ0** = feature Ã  supprimer

### La MulticollinÃ©aritÃ©
Heatmap montre corrÃ©lations >0.7 entre pixels voisins (logique gÃ©omÃ©trique)
* RF gÃ¨re bien, mais rÃ©gression linÃ©aire planterait

---

## 5. Analyse Approfondie : MÃ©thodologie (Split)

### Le Concept : Garantie de GÃ©nÃ©ralisation
80/20 Pareto : assez de Train pour apprendre, assez de Test pour juger

### ParamÃ¨tres critiques
```
test_size=0.2 â†’ 360 images test
random_state=42 â†’ science reproductible
stratify=y â†’ 10% chaque chiffre Train ET Test
```

---

## 6. FOCUS THÃ‰ORIQUE : Random Forest ðŸŒ² (200 arbres)

### A. Faiblesse Arbre unique
Overfit : `pixel_13>8.2 AND pixel_20<3.1 â†’ "4"` (rÃ¨gle trop spÃ©cifique)

### B. Force du Groupe
1. **Bootstrap** : Arbre#1 voit patients A,B,C ; Arbre#2 voit A,C,D
2. **Feature Randomness** : $\\sqrt{64}=8$ pixels alÃ©atoires par split
3. **Vote majoritaire** : Erreurs individuelles s'annulent

### C. Parfait pour Digits
* 64 features corrÃ©lÃ©es â†’ OK
* 10 classes â†’ vote robuste
* Bruit pixels â†’ rÃ©sistant

---

## 7. Analyse Approfondie : Ã‰valuation

### A. Matrice Confusion (10Ã—10)
```
Diagonale : 95%+ accuracy
Confusions : 3â†”5, 4â†”9 (traits similaires)
```

### B. MÃ©triques avancÃ©es
```
Precision 9: 0.97 â†’ "9" prÃ©dit = VRAI 9
Recall 4: 0.94 â†’ 94% vrais "4" dÃ©tectÃ©s
F1 macro: 0.96 â†’ performance homogÃ¨ne
```

### Conclusion Projet
**Data Science â‰  model.fit()**. C'est une chaÃ®ne mÃ©tier-ML :
1. **OCR â†’ Digits** : 64 pixels â†’ classifieur
2. **Wrangling â†’ EDA** : 5760 NaN â†’ corrÃ©lations spatiales
3. **Split â†’ RF** : 80/20 stratifiÃ© â†’ 96% F1
4. **Audit** : confusions 3/5/4/9 â†’ CNN next

**LeÃ§ons** :
- Pipeline > code brut
- Visualisez la matrice confusion
- `Pipeline()` corrige data leakage
```


