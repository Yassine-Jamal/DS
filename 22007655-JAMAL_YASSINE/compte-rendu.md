yassine jamal

<img src="https://www.encgs.ac.ma/wp-content/uploads/2024/06/logo.png"
     alt="Logo ENCG Settat"
     style="height:300px; margin-right:300px; float:left; border-radius:10px;">
---
# ðŸ“˜ GRAND GUIDE : ANATOMIE D'UN PROJET DATA SCIENCE - DIGITS

Ce document dÃ©cortique chaque Ã©tape du cycle de vie d'un projet de Machine Learning sur le dataset **Digits**. Il est conÃ§u pour passer du niveau "dÃ©butant qui copie du code" au niveau "ingÃ©nieur qui comprend les mÃ©canismes internes".

---

## 1. Le Contexte MÃ©tier et la Mission

### Le ProblÃ¨me (Business Case)
Dans le domaine de la reconnaissance optique de caractÃ¨res (OCR), identifier automatiquement des chiffres manuscrits accÃ©lÃ¨re le traitement de documents scannÃ©s (factures, formulaires bancaires).

*   **Objectif :** CrÃ©er un "Assistant IA" pour lire automatiquement les chiffres manuscrits 0-9
*   **L'Enjeu critique :** La matrice des coÃ»ts d'erreur est asymÃ©trique
    *   Dire "1" au lieu de "7" = erreur bancaire
    *   Dire "0" au lieu de "6" = erreur de lecture de compte
    *   **L'IA doit prioriser la prÃ©cision globale (>95%)**

### Les DonnÃ©es (L'Input)
Dataset **Digits** de Scikit-Learn
*   **X (Features) :** 64 colonnes (pixels d'images 8x8 aplaties). IntensitÃ©s 0-16
*   **y (Target) :** Multi-classe 0-9 (10 chiffres manuscrits)
*   **Taille :** 1797 images

---

## 2. Le Code Python (Laboratoire)

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Configuration
sns.set_theme(style="whitegrid")
import warnings
warnings.filterwarnings('ignore')

# --- PHASE 1 : ACQUISITION & SIMULATION ---
data = load_digits()
df = pd.DataFrame(data.data, columns=[f"pixel_{i}" for i in range(data.data.shape[1])])
df['target'] = data.target

# Simulation de la rÃ©alitÃ© (DonnÃ©es sales) - 5% NaN
np.random.seed(42)
df_dirty = df.copy()
for col in df.columns[:-1]:
    df_dirty.loc[df_dirty.sample(frac=0.05).index, col] = np.nan

# --- PHASE 2 : DATA WRANGLING (NETTOYAGE) ---
X = df_dirty.drop('target', axis=1)
y = df_dirty['target']

# StratÃ©gie d'imputation
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)
X_clean = pd.DataFrame(X_imputed, columns=X.columns)

# --- PHASE 3 : ANALYSE EXPLORATOIRE (EDA) ---
print("--- Statistiques Descriptives ---")
print(X_clean.iloc[:, :10].describe())

# Visualisation images
plt.figure(figsize=(10, 3))
for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.imshow(data.images[i], cmap="gray")
    plt.title(f"Label : {data.target[i]}")
    plt.axis("off")
plt.suptitle("Exemples d'images Digits", fontsize=14)
plt.tight_layout()
plt.show()

# --- PHASE 4 : PROTOCOLE EXPÃ‰RIMENTAL (SPLIT) ---
X_train, X_test, y_train, y_test = train_test_split(
    X_clean, y, test_size=0.2, random_state=42, stratify=y
)

# --- PHASE 5 : INTELLIGENCE ARTIFICIELLE (RANDOM FOREST) ---
model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

# --- PHASE 6 : AUDIT DE PERFORMANCE ---
y_pred = model.predict(X_test)

print(f"\n--- Accuracy Globale : {accuracy_score(y_test, y_pred)*100:.2f}% ---")
print("\n--- Rapport DÃ©taillÃ© ---")
print(classification_report(y_test, y_pred, target_names=[str(i) for i in range(10)]))

# Visualisation des erreurs
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Matrice de Confusion : RÃ©alitÃ© vs IA')
plt.ylabel('Vrai Chiffre')
plt.xlabel('Chiffre PrÃ©dit')
plt.show()
```


---

## 3. Analyse Approfondie : Nettoyage (Data Wrangling)

### Le ProblÃ¨me MathÃ©matique du Â« Vide Â»

Les algorithmes de Machine Learning ne savent pas manipuler les valeurs `NaN`. Une seule valeur manquante dans un vecteur peut faire Ã©chouer le calcul de distances ou de probabilitÃ©s. 
Dans ce projet, 5â€¯% des valeurs de chaque feature ont Ã©tÃ© remplacÃ©es par `NaN`, soit plusieurs milliers de Â« trous Â» Ã  combler avant dâ€™entraÃ®ner un modÃ¨le. 

### La MÃ©canique de lâ€™Imputation

On utilise `SimpleImputer(strategy="mean")` qui suit deux Ã©tapes :
1. **Apprentissage (`fit`) :**  
   Pour chaque colonne `pixel_i`, lâ€™algorithme calcule la moyenne \(\mu_i\) des valeurs non manquantes et la stocke.

2. **Transformation (`transform`) :**  
   Chaque `NaN` de `pixel_i` est remplacÃ© par \(\mu_i\), ce qui donne une matrice `X_clean` entiÃ¨rement numÃ©rique, sans valeurs manquantes.

RÃ©sultat : les modÃ¨les basÃ©s sur lâ€™algÃ¨bre linÃ©aire (et ici le Random Forest) peuvent fonctionner sans erreur liÃ©e aux `NaN`. 
### ðŸ’¡ Le Coin de lâ€™Expert (Data Leakage)

Dans ce script, le nettoyage est fait **avant** la sÃ©paration Train/Test. 

- **ProblÃ¨me :** Les moyennes utilisÃ©es pour imputer le Test Set ont Ã©tÃ© calculÃ©es en utilisant Ã©galement les donnÃ©es du Test â†’ fuite dâ€™information (Â« Data Leakage Â»). 
- **Bonne pratique absolue :**  
  - Faire le split Train/Test en premier.  
  - Apprendre les moyennes (`fit`) uniquement sur le Train.  
  - Appliquer la transformation (`transform`) sur le Test avec ces mÃªmes moyennes (souvent via un `Pipeline` Scikit-Learn).

---

## 4. Analyse Approfondie : Exploration (EDA)

### DÃ©crypter `.describe()`

Les statistiques descriptives sur les 10 premiers pixels donnent un premier profil du dataset Digits : 

- Des pixels avec `mean = 0` et `std = 0` (comme certains pixels de bord) nâ€™apportent aucune information utile, car ils sont toujours noirs.  
- Des pixels centraux ont des moyennes et des Ã©cartsâ€‘types plus Ã©levÃ©s, montrant quâ€™ils captent la forme des chiffres. 

Comparer **mean** et **50â€¯% (mÃ©diane)** permet de repÃ©rer des distributions asymÃ©triques (skewness) : une moyenne beaucoup plus Ã©levÃ©e que la mÃ©diane peut indiquer la prÃ©sence de quelques intensitÃ©s trÃ¨s fortes. 

### Les Visualisations ClÃ©s

Trois visualisations structurent le Â« profilage Â» : 

- **Panel dâ€™images 8Ã—8** : montrer visuellement quelques chiffres (0â€“9) permet de relier les intensitÃ©s de pixels Ã  des formes concrÃ¨tes.  
- **Distribution de `pixel_20` par classe** : visualiser lâ€™histogramme de ce pixel pour chaque chiffre permet de voir si ce pixel est discriminant.  
- **Matrice de corrÃ©lation (20 premiers pixels)** : la heatmap met en Ã©vidence des groupes de pixels trÃ¨s corrÃ©lÃ©s, souvent voisins dans lâ€™image, ce qui reflÃ¨te la structure gÃ©omÃ©trique des chiffres manuscrits.  

---

## 5. Analyse Approfondie : MÃ©thodologie (Split)

### Le Concept : La Garantie de GÃ©nÃ©ralisation

Le but du Machine Learning est de **gÃ©nÃ©raliser** sur de nouveaux chiffres manuscrits, pas dâ€™apprendre par cÅ“ur les 1â€¯797 exemples.   
Un split **80â€¯% / 20â€¯%** permet :

- Dâ€™avoir suffisamment de donnÃ©es pour apprendre la variabilitÃ© de lâ€™Ã©criture.  
- De rÃ©server un jeu de test indÃ©pendant pour estimer la performance en situation rÃ©elle.  

### Les ParamÃ¨tres sous le Capot

Lâ€™appel Ã  `train_test_split` utilise :

- `test_size=0.2` : â‰ˆ 360 images de test.  
- `random_state=42` : graine fixÃ©e pour un partitionnement reproductible.  
- `stratify=y` : garantie que chaque classe (0â€“9) est reprÃ©sentÃ©e de maniÃ¨re Ã©quilibrÃ©e dans Train et Test.

Sans `stratify`, certaines classes rares pourraient Ãªtre sousâ€‘reprÃ©sentÃ©es dans le jeu de test, faussant lâ€™analyse des performances par chiffre. 

---

## 6. FOCUS THÃ‰ORIQUE : Lâ€™Algorithme Random Forest ðŸŒ²

### A. La Faiblesse de lâ€™Arbre IsolÃ©

Un seul arbre de dÃ©cision apprend une succession de rÃ¨gles du type :  
Â« si tel pixel > seuil et tel autre pixel < seuil, alors chiffre = 3 Â».  
Ce type de modÃ¨le a une **variance Ã©levÃ©e** : il peut surapprendre des dÃ©tails spÃ©cifiques Ã  lâ€™Ã©chantillon dâ€™entraÃ®nement (overfitting). 

### B. La Force du Groupe (Bagging + AlÃ©a)

Le Random Forest construit une forÃªt dâ€™arbres hÃ©tÃ©rogÃ¨nes grÃ¢ce Ã  deux sources dâ€™alÃ©a : 

1. **Bootstrapping des donnÃ©es**  
   Chaque arbre est entraÃ®nÃ© sur un Ã©chantillon tirÃ© avec remise du jeu dâ€™entraÃ®nement (certains exemples sont rÃ©pÃ©tÃ©s, dâ€™autres absents).

2. **AlÃ©a sur les features**  
   Ã€ chaque split, lâ€™arbre ne choisit la meilleure coupure quâ€™au sein dâ€™un sousâ€‘ensemble alÃ©atoire de pixels, ce qui diversifie les rÃ¨gles apprises.

En prÃ©diction, les arbres votent, et la classe finale est choisie par **majoritÃ©**. Les erreurs individuelles se compensent, et le modÃ¨le final est plus stable. 

### C. Pourquoi Random Forest est adaptÃ© Ã  Digits

- Il gÃ¨re bien les **features corrÃ©lÃ©es** (pixels voisins dans lâ€™image).  
- Il supporte nativement les problÃ¨mes **multiâ€‘classes** (10 chiffres). 
- Il est robuste au **bruit** et aux petites variations dâ€™Ã©criture. 

---

## 7. Analyse Approfondie : Ã‰valuation (Lâ€™Heure de VÃ©ritÃ©)

### A. Accuracy Globale

Le modÃ¨le Random Forest obtient une **accuracy supÃ©rieure Ã  95â€¯%** sur le jeu de test, ce qui signifie que la majoritÃ© Ã©crasante des chiffres manuscrits est correctement reconnue.

### B. Rapport de Classification

Le rapport de classification (`classification_report`) donne, pour chaque chiffre de 0 Ã  9 : 

- **Precision** : quand le modÃ¨le prÃ©dit ce chiffre, Ã  quel point il a raison.  
- **Recall** : parmi tous les exemples de ce chiffre, combien il en dÃ©tecte correctement.  
- **F1â€‘score** : synthÃ¨se Ã©quilibrÃ©e des deux prÃ©cÃ©dents.

Les scores sont Ã©levÃ©s et relativement homogÃ¨nes entre les classes, ce qui montre que le modÃ¨le ne se contente pas dâ€™Ãªtre bon sur une seule classe comme le 0 ou le 1, mais fonctionne bien sur lâ€™ensemble des chiffres. 

### C. La Matrice de Confusion

La matrice de confusion (10Ã—10) est visualisÃ©e sous forme de heatmap : 

- La **diagonale** regroupe les prÃ©dictions correctes (vrai chiffre = chiffre prÃ©dit).  
- Les **valeurs hors diagonale** rÃ©vÃ¨lent les confusions (par exemple certains 3 pris pour des 5, certains 4 pris pour des 9).  

Ces motifs dâ€™erreurs donnent des pistes dâ€™amÃ©lioration :  
- ModÃ¨les plus spÃ©cialisÃ©s (par exemple CNN).  
- Features additionnelles plus adaptÃ©es Ã  la structure 2D des images.

---

## Conclusion du Projet

Ce rapport montre que la Data Science ne sâ€™arrÃªte pas Ã  `model.fit()`. Câ€™est une chaÃ®ne de dÃ©cisions logiques oÃ¹ : 

- Le **contexte mÃ©tier** (OCR) guide le choix des donnÃ©es (Digits 8Ã—8) et des mÃ©triques (accuracy, F1 par chiffre).  
- Le **pipeline technique** (simulation de NaN, imputation, EDA, split stratifiÃ©) prÃ©pare un terrain propre pour le modÃ¨le.  
- Lâ€™algorithme **Random Forest** fournit une solution robuste et performante Ã  un problÃ¨me multiâ€‘classes rÃ©el.  
- Lâ€™**audit de performance** (rapport de classification, matrice de confusion) permet dâ€™interprÃ©ter les rÃ©sultats et dâ€™identifier les axes dâ€™amÃ©lioration.
 
