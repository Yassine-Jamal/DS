# üßÆ PROJET DATA SCIENCE : RECONNAISSANCE DE CHIFFRES MANUSCRITS (DIGITS)

Ce document pr√©sente le cycle complet d‚Äôun mini-projet de Machine Learning appliqu√© au dataset **Digits** de Scikit-Learn, depuis le chargement des donn√©es jusqu‚Äô√† l‚Äôaudit de performance du mod√®le Random Forest.

---

## 1. Contexte et objectif

### Probl√®me trait√©
Le probl√®me consiste √† reconna√Ætre automatiquement des chiffres manuscrits √† partir d‚Äôimages 8x8 en niveaux de gris, chaque image repr√©sentant un chiffre entre 0 et 9.  
L‚Äôobjectif est de construire un mod√®le de classification supervis√©e capable de pr√©dire correctement le chiffre correspondant √† une nouvelle image manuscrite. 

### Donn√©es utilis√©es
Le dataset **Digits** contient‚ÄØ:  
- 1 797 observations, chacune correspondant √† une image 8x8 (soit 64 pixels) aplatie en vecteur de dimension 64.   
- Une cible `target` prenant des valeurs de 0 √† 9, repr√©sentant la classe du chiffre manuscrit. 

Les variables explicatives sont des intensit√©s de pixels (valeurs enti√®res entre 0 et 16), et la variable cible est un entier indiquant le chiffre manuscrit.

---

## 2. Laboratoire Python (script Colab)

### Biblioth√®ques et chargement du dataset
Le script importe les principales biblioth√®ques de data science‚ÄØ: NumPy, pandas, Matplotlib, Seaborn et plusieurs modules de Scikit-Learn (chargement du dataset, split, imputation, RandomForest, m√©triques).  
Le dataset **Digits** est charg√© via `load_digits()`, puis transform√© en `DataFrame` pour les features (colonnes `pixel_0` √† `pixel_63`) et en `Series` pour la cible `target`. 

### Structure g√©n√©rale du code
Le notebook suit une structure p√©dagogique claire‚ÄØ:  
1. Importation des biblioth√®ques. 
2. Chargement et inspection du dataset.  
3. Simulation de donn√©es manquantes.   
4. Nettoyage / imputation.   
5. Analyse exploratoire (statistiques + visualisations).  
6. D√©coupage Train / Test.  
7. Entra√Ænement d‚Äôun mod√®le Random Forest.   
8. √âvaluation via accuracy, rapport de classification et matrice de confusion. 

---

## 3. Nettoyage des donn√©es (Data Wrangling)

### Simulation des valeurs manquantes
Pour rendre l‚Äôexercice plus r√©aliste, des valeurs manquantes artificielles sont introduites‚ÄØ:  
- Pour chaque pixel (chaque colonne de feature), 5‚ÄØ% des lignes sont remplac√©es par `NaN`.   
- Le nombre total de valeurs manquantes g√©n√©r√©es atteint 5‚ÄØ760, ce qui correspond √† une perturbation significative sur l‚Äôensemble des features. 

Ce choix permet de tester une vraie √©tape de **gestion des donn√©es incompl√®tes**, fr√©quente en production. 

### Imputation et reconstruction du jeu propre
Le nettoyage est r√©alis√© en deux temps‚ÄØ:  
- S√©paration des donn√©es en `X` (toutes les colonnes de pixels) et `y` (colonne `target`).   
- Application d‚Äôun `SimpleImputer(strategy="mean")` sur `X` pour remplacer chaque `NaN` par la moyenne de la colonne correspondante, puis reconstruction d‚Äôun `DataFrame` `X_clean`. 

Apr√®s imputation, le script v√©rifie qu‚Äôil ne reste plus aucune valeur manquante, ce qui garantit que les algorithmes de Machine Learning pourront fonctionner correctement. 

---

## 4. Analyse exploratoire (EDA)

### Statistiques descriptives des pixels
Le script affiche `.describe()` pour les 10 premiers pixels (`pixel_0` √† `pixel_9`).   
On observe notamment‚ÄØ:  
- Des minimums √† 0 et des maximums √† 16, coh√©rents avec l‚Äô√©chelle des intensit√©s de gris du dataset Digits.   
- Des distributions o√π la m√©diane et la moyenne peuvent diverger, indiquant parfois des distributions asym√©triques selon le pixel. 

### Visualisation des images et distributions
Plusieurs visualisations compl√®tent le profilage‚ÄØ:  
- Un panel de 10 images 8x8 est affich√© avec leur label r√©el, ce qui donne une intuition qualitative de la difficult√© du probl√®me.   
- Une distribution d‚Äôun pixel choisi (`pixel_20`) est trac√©e en fonction de la classe `target`, illustrant comment une m√™me zone de l‚Äôimage peut porter une information discriminante selon le chiffre. 

### Corr√©lations entre features
Une matrice de corr√©lation est calcul√©e sur les 20 premiers pixels puis visualis√©e par une heatmap Seaborn.   
Cette visualisation permet d‚Äôidentifier des groupes de pixels fortement corr√©l√©s, souvent voisins dans l‚Äôimage, refl√©tant la structure spatiale des chiffres manuscrits. 

---

## 5. M√©thodologie exp√©rimentale (Train / Test Split)

### Strat√©gie de d√©coupage
La s√©paration des donn√©es se fait via `train_test_split` avec les param√®tres‚ÄØ:  
- `test_size=0.2` pour garder 20‚ÄØ% des donn√©es pour le test (environ 360 √©chantillons).  
- `random_state=42` pour la reproductibilit√© des r√©sultats.  
- `stratify=y` pour conserver la m√™me proportion de chaque chiffre dans les ensembles d‚Äôentra√Ænement et de test. 

Cette strat√©gie garantit‚ÄØ:  
- Un apprentissage sur une base suffisamment riche (80‚ÄØ% des donn√©es). 
- Une √©valuation fiable sur un √©chantillon repr√©sentatif et √©quilibr√© des classes. 

---

## 6. Mod√®le de Machine Learning : Random Forest

### Choix de l‚Äôalgorithme
Le mod√®le utilis√© est un **RandomForestClassifier**, bien adapt√© aux probl√®mes de classification multi-classes comme Digits (10 classes de 0 √† 9).  
Les hyperparam√®tres principaux sont‚ÄØ:  
- `n_estimators=200` (nombre d‚Äôarbres dans la for√™t).   
- `max_depth=None` (profondeur non limit√©e, laiss√©e √† l‚Äôalgorithme). 
- `random_state=42` et `n_jobs=-1` pour la reproductibilit√© et l‚Äôexploitation de tous les c≈ìurs CPU. 

### Entra√Ænement
Le mod√®le est entra√Æn√© sur `X_train` et `y_train` via `model.fit`.   
Cette √©tape apprend les motifs entre combinaisons de pixels et classes de chiffres manuscrits sur l‚Äôensemble d‚Äôentra√Ænement nettoy√©. 

---

## 7. √âvaluation du mod√®le

### Accuracy globale
L‚Äôaccuracy est calcul√©e sur le jeu de test‚ÄØ:  
- Le score obtenu est d‚Äôenviron **plus de 95‚ÄØ%** (pr√©cision globale tr√®s √©lev√©e sur la classification des chiffres).  
- Cela montre que le Random Forest capture efficacement la structure des chiffres manuscrits dans ce dataset. 

### Rapport de classification
Le rapport d√©taill√© (`classification_report`) fournit, pour chaque classe 0‚Äì9‚ÄØ:  
- La pr√©cision (precision), le rappel (recall) et le F1-score.  
- Des scores globalement √©lev√©s et homog√®nes, ce qui indique que le mod√®le ne se contente pas de bien pr√©dire quelques chiffres seulement. 

### Matrice de confusion
Une matrice de confusion est trac√©e via `sns.heatmap`, avec les chiffres r√©els en ordonn√©e et les pr√©dictions en abscisse. [file:2]  
Elle montre que‚ÄØ:  
- La majorit√© des pr√©dictions sont sur la diagonale, signe d‚Äôune bonne classification.  
- Quelques confusions subsistent entre certains chiffres visuellement proches (par exemple 3/5 ou 4/9), ce qui donne des pistes pour de futures am√©liorations. 

---

## 8. Lecture critique et axes d‚Äôam√©lioration

### Points forts de la d√©marche
- Pipeline complet : du chargement des donn√©es au reporting final, avec une structure claire et p√©dagogique.  
- Gestion explicite des valeurs manquantes et v√©rification post-imputation. 
- Utilisation de visualisations pertinentes (images, distributions, corr√©lations, matrice de confusion). 
- Mod√®le robuste (Random Forest) capable de g√©rer des features corr√©l√©es et d‚Äôobtenir une haute accuracy sur un probl√®me multi-classes.

### Limites et pistes d‚Äôextension
- L‚Äôimputation est faite sur l‚Äôensemble des donn√©es avant le split, ce qui serait √† corriger dans un pipeline industriel (risque de **data leakage**).   
- Une exploration d‚Äôautres mod√®les (par exemple SVM ou r√©seaux de neurones) ou un tuning plus syst√©matique des hyperparam√®tres pourrait encore am√©liorer la performance. 

---

## 9. Conclusion

Ce projet illustre un **cycle de vie complet** en Data Science sur un probl√®me de vision simple :  
- Pr√©paration et nettoyage d‚Äôun dataset d‚Äôimages vectoris√©es.   
- Analyse exploratoire pour comprendre les distributions de pixels et leurs liens avec les classes.   
- Mod√©lisation avec un algorithme robuste (Random Forest) et √©valuation fine via plusieurs m√©triques et visualisations. 

L‚Äôensemble du travail montre comment transformer un notebook Colab en un v√©ritable **projet structur√©** de reconnaissance de chiffres manuscrits. 
