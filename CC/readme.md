# JAMAL YASSINE

<img src="JAMAL YASSINE CAC2.jpg" style="height:464px;margin-right:432px"/>

# CAC2

# 22007655


# Compte rendu

## Analyse complÃ¨te

# DÃ©tection de Fraude aux Cartes de CrÃ©dit

## Contexte
Dans un contexte de digitalisation accÃ©lÃ©rÃ©e des paiements, la fraude aux cartes de crÃ©dit reprÃ©sente un enjeu Ã©conomique majeur pour les institutions financiÃ¨res, avec des pertes estimÃ©es Ã  plusieurs milliards d'euros annuellement. Ce projet de Data Science, rÃ©alisÃ© dans le cadre d'un module Machine Learning, vise Ã  dÃ©velopper un systÃ¨me prÃ©dictif capable d'identifier les transactions frauduleuses en temps rÃ©el Ã  partir du dataset Kaggle "Credit Card Fraud Detection" (284 807 transactions europÃ©ennes sur 2 jours, 0,172% de fraudes).

## ProblÃ©matique
Classification binaire supervisÃ©e sur donnÃ©es hautement dÃ©sÃ©quilibrÃ©es : prÃ©dire la variable cible 'Class' (0=lÃ©gitime, 1=fraude) en exploitant 28 features anonymisÃ©es (PCA), 'Time' et 'Amount'. L'objectif est de minimiser les faux nÃ©gatifs tout en optimisant Precision/Recall via SMOTE, cross-validation et hyperparamÃ©trage. ThÃ©matique : Ã‰conomie/Finance. 

## MÃ©thodologie
- **Preprocessing** : Nettoyage, feature engineering (Amount_log), RobustScaler
- **EDA** : Visualisations distributions/corrÃ©lations, interprÃ©tations
- **ModÃ©lisation** : 3 algorithmes (LogisticRegression, RandomForest, XGBoost) + GridSearchCV
- **Ã‰valuation** : ROC-AUC, F1-Score, matrice de confusion

- # ğŸ“„ Compte rendu â€“ DÃ©tection de fraude sur transactions bancaires par apprentissage supervisÃ©

## 1. ğŸ“ Ã€ propos du jeu de donnÃ©es  
Le travail repose sur le dataset **Credit Card Fraud Detection** provenant de Kaggle, composÃ© de **284 807 transactions** dÃ©crites par **31 variables** :  
- **28 variables anonymisÃ©es** (`V1`â€“`V28`), issues dâ€™une transformation PCA ;  
- **2 variables originales** (`Time` et `Amount`) ;  
- **1 variable cible (`Class`)** indiquant :  
  - `0` = transaction lÃ©gitime,  
  - `1` = transaction frauduleuse.  

Le dataset est **extrÃªmement dÃ©sÃ©quilibrÃ©**, ne contenant que **492 fraudes** pour **284 315 transactions normales**, soit un taux de fraude dâ€™environ **0,17 %**.  
Ce dÃ©sÃ©quilibre impose lâ€™utilisation de techniques adaptÃ©es pour lâ€™apprentissage supervisÃ©.

---

## 2. ğŸ¯ Introduction et contexte  
La dÃ©tection de fraude bancaire constitue un enjeu crucial pour les institutions financiÃ¨res, qui doivent identifier rapidement les transactions suspectes tout en limitant les fausses alertes.  

Lâ€™objectif de ce projet est de construire un modÃ¨le dâ€™apprentissage supervisÃ© capable de :  
- dÃ©tecter efficacement les transactions frauduleuses,  
- rÃ©duire les pertes financiÃ¨res associÃ©es aux fraudes non dÃ©tectÃ©es,  
- maintenir un niveau faible de faux positifs pour prÃ©server lâ€™expÃ©rience client.

Dans un contexte de classes trÃ¨s dÃ©sÃ©quilibrÃ©es, les mÃ©triques traditionnelles comme lâ€™accuracy sont **insuffisantes**.  
Les indicateurs prioritaires sont :  
- **Recall**, pour Ã©viter les faux nÃ©gatifs,  
- **PrÃ©cision**,  
- **F1-score**,  
- **ROC-AUC**, adaptÃ© aux dÃ©sÃ©quilibres extrÃªmes.

---

## 3. ğŸ“Š Analyse exploratoire (EDA)  
Lâ€™analyse exploratoire rÃ©alisÃ©e confirme les Ã©lÃ©ments clÃ©s suivants :

### âœ” DÃ©sÃ©quilibre massif  
La classe `1` reprÃ©sente moins de 1 transaction sur 500.

### âœ” Variables PCA  
Les composantes `V1` Ã  `V28` sont dÃ©jÃ  centrÃ©es-rÃ©duites.  
Certaines variables (ex. `V14`, `V17`) montrent des distributions distinctes entre fraudes et non-fraudes, suggÃ©rant une bonne sÃ©parabilitÃ©.

### âœ” Montant des transactions  
`Amount` prÃ©sente une distribution trÃ¨s asymÃ©trique.  
Une transformation logarithmique est pertinente pour rÃ©duire cette asymÃ©trie.

### âœ” CorrÃ©lations  
La matrice de corrÃ©lation montre trÃ¨s peu de relations linÃ©aires fortes en raison de la PCA, mais certaines variables se dÃ©marquent dans les cas de fraude.

---

## 4. ğŸ”§ PrÃ©paration et ingÃ©nierie des donnÃ©es

### âœ” Suppression des doublons  
Les doublons dÃ©tectÃ©s ont Ã©tÃ© supprimÃ©s pour Ã©viter un biais dans l'apprentissage.

### âœ” CrÃ©ation de nouvelles variables  
Ã€ partir de `Amount`, deux nouvelles caractÃ©ristiques utiles ont Ã©tÃ© ajoutÃ©es :  
- `Amount_Scaled` (scalÃ©e via `RobustScaler`),  
- `Log_Amount` (transformation logarithmique).

### âœ” Standardisation  
Les colonnes `Time` et `Amount` brutes ont Ã©tÃ© retirÃ©es, car leur version transformÃ©e est plus pertinente pour la modÃ©lisation.

### âœ” DÃ©coupage du dataset  
Un split **80 % / 20 %** a Ã©tÃ© rÃ©alisÃ© avec **stratification sur `Class`** afin de conserver la proportion de fraudes dans chaque sous-Ã©chantillon.

---

## 5. ğŸ¤– MÃ©thodologie de modÃ©lisation

Trois algorithmes supervisÃ©s ont Ã©tÃ© Ã©tudiÃ©s :  
- **RÃ©gression Logistique**,  
- **Random Forest**,  
- **XGBoost**.

### âœ” Gestion du dÃ©sÃ©quilibre  
La technique **SMOTE** est utilisÃ©e dans un pipeline pour sur-Ã©chantillonner la classe minoritaire **uniquement sur les donnÃ©es dâ€™entraÃ®nement**, Ã©vitant toute fuite dâ€™information.  

### âœ” Validation croisÃ©e et optimisation  
Chaque modÃ¨le est intÃ©grÃ© dans un pipeline comprenant :  
- standardisation des donnÃ©es,  
- oversampling (SMOTE),  
- classification.

La recherche dâ€™hyperparamÃ¨tres est rÃ©alisÃ©e via **GridSearchCV**, avec comme scoring principal :  
â¡ï¸ `roc_auc`, adaptÃ© au dÃ©sÃ©quilibre extrÃªme.

Cette configuration permet une Ã©valuation robuste et cohÃ©rente de chaque modÃ¨le.

---

## 6. ğŸ“ˆ RÃ©sultats, limites et recommandations

### âœ” RÃ©sultats observÃ©s  
Les premiers tests montrent que :  
- lâ€™accuracy nâ€™est pas pertinente (trop influencÃ©e par la classe majoritaire),  
- le **ROC-AUC** est nettement plus reprÃ©sentatif des performances,  
- les mÃ©triques clÃ©s pour la classe de fraude sont le **Recall**, la **PrÃ©cision** et le **F1-Score**.

Les modÃ¨les avancÃ©s comme **Random Forest** et **XGBoost** montrent un fort potentiel pour amÃ©liorer la dÃ©tection des fraudes.

### âœ” Limites rencontrÃ©es  
- Configuration initiale du scoring dans GridSearch nÃ©cessitant une correction (`scoring="roc_auc"`).  
- Faible nombre relatif de fraudes entraÃ®nant une variabilitÃ© Ã©levÃ©e sur les mesures de performances.  
- Les variables PCA ne permettent pas une interprÃ©tation mÃ©tier directe.

### âœ” Recommandations  
- Finaliser lâ€™optimisation des hyperparamÃ¨tres.  
- Explorer lâ€™utilisation dâ€™algorithmes supplÃ©mentaires (Isolation Forest, modÃ¨les neuronaux).  
- GÃ©nÃ©rer un tableau comparatif complet des rÃ©sultats (AUC, Recall, F1â€¦).  
- Mettre en place un modÃ¨le en production avec seuil de dÃ©cision ajustable.

---

## 7. ğŸ Conclusion  
Ce projet illustre les dÃ©fis de la dÃ©tection de fraude sur des donnÃ©es massives et fortement dÃ©sÃ©quilibrÃ©es.  
La chaÃ®ne dâ€™analyse mise en place â€” nettoyage, ingÃ©nierie de variables, rÃ©Ã©quilibrage, validation croisÃ©e â€” Ã©tablit une base solide pour sÃ©lectionner le modÃ¨le le plus performant.
 
- finaliser le tuning des modÃ¨les,  
- comparer leurs performances avec des mÃ©triques robustes,  
- choisir la solution offrant le meilleur compromis entre dÃ©tection des fraudes et rÃ©duction des faux positifs.

Ce travail constitue une avancÃ©e significative vers la crÃ©ation dâ€™un systÃ¨me fiable de dÃ©tection de fraude bancaire.


